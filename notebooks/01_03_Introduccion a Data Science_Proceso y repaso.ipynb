{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/efviodo/idatha-data-science-course/blob/master/notebooks/02%20-%20DS%20-%20Introduccion%20a%20Data%20Science%20-%20Python.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/efviodo/idatha-data-science-course/raw/master/notebooks/figures/idatha-logo.jpeg\" width=\"100px\" height=\"100px\" style=\"float:left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la Ciencia de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos\n",
    "\n",
    "- Conocer conceptos básicos de Data Sience\n",
    "- Entender qué problemas se resuelven en Data Sience\n",
    "- Introducir una metodología de trabajo para Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Indice'></a>\n",
    "## Índice\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "1. [Data Science](#Data-Sience)\n",
    "1. [Data Scientist](#Data-Scientist)\n",
    "1. [Conceptos Básicos](#Conceptos-basicos)\n",
    "1. [Aplicaciones de Data Science](#Aplicaciones-Data-Science)\n",
    "1. [Metodologias](#Metodologias)\n",
    "    1. [Modelo CRISP-DM](#Modelo-CRISP-DM)\n",
    "        1. [Comprensión del Negocio](#Comprension-Negocio)\n",
    "        1. [Comprensión de los Datos](#Comprension-Datos)\n",
    "        1. [Preparación de los Datos](#Preparacion-Datos)\n",
    "        1. [Evaluación](#Evaluacion)\n",
    "        1. [Despliegue](#Despliegue)\n",
    "1. [Herramientas](#Herramientas)\n",
    "1. [Bibliografía](#Bibliografia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data-Sience'></a>\n",
    "## Data Sience\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "La ciencia de datos es un campo interdisciplinario que involucra métodos científicos, procesos y sistemas para extraer conocimiento o alcanzar un mejor entendimiento de datos en sus diferentes formas (estructurados y no estructurados). Para ello se basa en algunos campos del análisis de datos como la estadística, la minería de datos, el aprendizaje automático y la analítica predictiva.\n",
    "\n",
    "En otras palabras, puede imaginarse como un área de conocimiento que se basa en otras áreas ya desarrolladas, como la Minería de Datos, Análisis Estadístico y utiliza técnicas de Aprendizaje Automático y BigData para descubrir nueva información.\n",
    "\n",
    "<br />\n",
    "\n",
    "![figure1](https://github.com/efviodo/data-science/raw/master/courses/utec/figures/data_disciplines.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Data-Scientist'></a>\n",
    "## Data Scientist\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "El Data Scientist o Científico de Datos, es una persona capaz de analizar e interpretar datos complejos, así como utilizar tecnicas de estadística y aprendizaje automático para comprender mejor estos datos y extraer conslusiones que permitan resolver un problema de la realidad.\n",
    "\n",
    "Combina una sólida formación teórica y práctica en las materias fundamentales asociadas al análisis avanzado de datos: pensamiento analítico, comprensión de problemas de la realidad, estadística, programación, tratamiento de bases de datos, trabajo con algoritmos y comunicación efectiva, preparado para encarar problemas de la realidad y convertirlos en soluciones utilizando datos. \n",
    "\n",
    "Es muy común colcoar a un data scientist en la intersección de las siguientes áreas de conocimento: (i) Ciencias de la Computación, (ii) Matemáticas y Estadística y (iii) Conocimiento de un dominio específico\n",
    "\n",
    "![figure1](https://github.com/efviodo/data-science/raw/master/courses/utec/figures/data_scientist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Conceptos-basicos'></a>\n",
    "## Conceptos Básicos\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "\n",
    "### Modelo \n",
    "Representación matemática de un proceso del mundo real; un modelo predictivo pronostica el resultado del futuro basado en comportamientos del pasado.\n",
    "\n",
    "*Ejemplo*: Modelo de probabilidad de fuga de clientes.\n",
    "\n",
    "### Algoritmo \n",
    "Conjunto ordenado de operaciones sistemáticas que permite hacer un cálculo y hallar la solución a un problema.\n",
    "\n",
    "*Ejemplo*: Algoritmo de ordenamiento [QuickSort](https://es.wikipedia.org/wiki/Quicksort).\n",
    "\n",
    "### Entrenamiento\n",
    "El proceso de crear un modelo a partir de los datos de entrenamiento. Los datos alimentan un algoritmo de entrenamiento que aprende la representación del problema y produce un modelo. Comúnmente llamado “aprendizaje”.\n",
    "\n",
    "### Regresión\n",
    "Método de predicción cuyo resultado es un número real (un valor que representa una cantidad en una recta). Por ejemplo: predecir la temperatura de un motor o la ganancia de una empresa.\n",
    "\n",
    "### Clasificación\n",
    "Método de predicción que asigna una categoría predefinida a cada dato de entrada, por ejemplo, categoría de cliente según sus compras.\n",
    "\n",
    "### Target \n",
    "En estadística se le llama variable dependiente. Es la salida del modelo o la variable que se quiere predecir.\n",
    "\n",
    "### Conjunto de Entrenamiento \n",
    "Comunmente llamado *Training dataset*, se utiliza para encontrar relaciones potencialmente predictivas que serán utilizadas para crear un modelo. También puede encontrarse como *Corpus de entrenamiento*.\n",
    "\n",
    "### Conjunto de Verificación\n",
    "Comunmente llamado *Test dataset*, es un conjunto de datos diferente al de entrenamiento, pero con la misma estructura. Se utiliza para evaluar la performance de los modelos predictivos. También puede encontrarse como *Corpus de pruebas*.\n",
    "\n",
    "### Feature \n",
    "También conocida como variable independiente o variable predictora, una feature es una cantidad observable, utilizada por un modelo predictivo. También se puede hacer ingeniería de features, creando nuevas variables a partir de la combinación de las mismas, pudiendo agregar información."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Aplicaciones-Data-Science'></a>\n",
    "## Aplicaciónes de Data Science\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "Ejemplos más comúnes:\n",
    "- Mantenimiento predictivo\n",
    "- Análisis de sentimiento\n",
    "- Detección de intereses\n",
    "- Segmentación de clientes\n",
    "- Riesgo de fuga\n",
    "- Detección de spam\n",
    "- Predicción de demanda\n",
    "- Detección de fraude\n",
    "\n",
    "### Ejemplos de aplicación por industria y vertical\n",
    "\n",
    "<br />\n",
    "\n",
    "![figure2](https://github.com/efviodo/data-science/raw/master/courses/utec/figures/data_science_applications.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Metodologias'></a>\n",
    "## Metodologías\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "### Motivación\n",
    "Necesito contar con una metodología o marco de trabajo que me permita sistematizar ciertas etapas como recolectar datos, limpiarlos, generar un modelo predictivo y determinar acciones. Un proceso estándar que traduzca un problema de la vida real en tareas abordables por un equipo de cientificos de datos.\n",
    "\n",
    "### Alternativas\n",
    "\n",
    "Existen varias propuestas de modelos o marcos de trabajo, que ayudan a un cientifico de datos a abordar un problema de forma ordenada. En este taller vamos a trabajar con un modelo bastante conocido, que se llama CRISP-DM y es bien conocido por ser uno de los modelos más adoptados para problemas en Minería de Datos.\n",
    "\n",
    "Cabe destcar, que existen otros modelos e incluso algunas empresas tecnológicas muy fuertes como Facebook y Uber, implementaron sus propias herramientas o plataformas para data science, basadas en sus propios modelos de trabajo.\n",
    "\n",
    "- [Microsoft TDSP](https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/), es una metodología o flujo de rabajo alternativa.\n",
    "- [FBLearner Flow](https://code.fb.com/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/), es una plataforma de Machine Learning de Facebook.\n",
    "\n",
    "\n",
    "Queda a cargo del lector profundizar en cualquiera de las alternativas propuestas o buscar nuevas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Modelo-Crisp-DM'></a>\n",
    "### Modelo CRISP-DM\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "\n",
    "CRISP-DM es la sigla para *CRoss Industry Standard Process for Data Mining* (algo así como *Proceso Estándar Multi Industria para Minería de Datos*). Es un modelo de proceso, propuesto inicialmente para proyectos de minería de datos y que puede ser adaptado para proyectos en ciencia de datos. El proceso es independiente del sector de la industira del cual proviene el problema que queremos resolver o de las tecnologías utilizadas. \n",
    "\n",
    "Fue presentado por primera vez en el año 2000, a través del trabajo *[CRISP-DM: Towards a standard process model for data mining](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.198.5133&rep=rep1&type=pdf)* [1]. En caso de estar interesado en el trabajo podes encontrar la cita en la sección de Biblografía.\n",
    "\n",
    "<br />\n",
    "\n",
    "<img src=\"https://github.com/efviodo/data-science/raw/master/courses/utec/figures/CRISP-DM_Process_Diagram.png\" alt=\"figure3\" style=\"width:400px\"/>\n",
    "\n",
    "En este taller veremos solamente las primeras tres fases del modelo, quedando fuera de alcance las otras tres.\n",
    "\n",
    "<a id='Fases-Modelo-Crisp-DM'></a>\n",
    "#### Fases del modelo CRISP-DM\n",
    "\n",
    "El modelo CRISP-DM se divide en 6 fases o etapas, que inicialmente en un proyecto de ciencia de datos se ejecutan en un orden determinado. Luego el proceso puede retro-alimentarse, volviendo a la etapa inicial o cualquier etapa intermedia, formando un circulo de retroalimentación.\n",
    "\n",
    "<a id='Comprension-Negocio'></a>\n",
    "#### I. Comprensión del negocio\n",
    "\n",
    "Comprensión de los objetivos y requisitos del proyecto desde una perspectiva empresarial, y luego convertir este conocimiento en una definición del problema de minería de datos, y un plan preliminar diseñado para alcanzar los objetivos.\n",
    "\n",
    "Etapas:\n",
    "\n",
    "- Determinar objetivos empresariales.\n",
    "- Analizar la situación actual.\n",
    "- Determinar objetivos de minería de datos.\n",
    "- Planificación con duración, recursos y riesgos.\n",
    "\n",
    "<a id='Comprension-Datos'></a>\n",
    "#### II. Comprensión de los datos\n",
    "\n",
    "Recolección inicial de datos y procesos con actividades con el objetivo de familiarizarse con los mismos, identificar problemas en la calidad de los datos, descubrir primeros insights en los datos, o detectar subconjuntos de datos para formular hipótesis sobre datos ocultos. Hay un vinculo muy cercano entre las etapas de *Comprensión del negocio* y *Comprensión de los datos*\n",
    "\n",
    "Etapas:\n",
    "\n",
    "- Recopilar datos disponibles\n",
    "- Explorar y describir los datos con tablas y gráficos.\n",
    "- Verificar calidad de los datos.\n",
    "\n",
    "<a id='Preparacion-Datos'></a>\n",
    "#### III. Preparación de datos\n",
    "\n",
    "Actividades para construir el conjunto de datos de entrenamiento. Estas tareas son ejecutadas en múltiples oportunidades y sin orden. Las tareas incluyen selección y transformación de tablas, registros y atributos, y limpieza de datos para las herramientas de modelado.\n",
    "\n",
    "Etapas:\n",
    "- Selección de subconjunto de datos.\n",
    "- Limpieza de datos.\n",
    "- Creación de nuevos atributos (ingeniería de atributos).\n",
    "- Fusión y agregado de conjuntos y registros.\n",
    "- Verificación de formato de datos para el modelado.\n",
    "- División en conjuntos de datos de prueba y entrenamiento.\n",
    "\n",
    "<a id='Modelado'></a>\n",
    "#### IV. Modelado\n",
    "\n",
    "Se seleccionan y aplican varias técnicas de modelado y se calibran los parámetros para mejorar los resultados. Hay varias técnicas que tienen requerimientos específicos sobre la forma de los datos, por lo que puede ser necesario volver a la fase de preparación de datos.\n",
    "\n",
    "<a id='Evaluacion'></a>\n",
    "#### V. Evaluación\n",
    "\n",
    "Evaluación del modelo (o modelos) construidos, que parecen tener gran calidad desde una perspectiva del análisis de datos.\n",
    "\n",
    "<a id='Despliegue'></a>\n",
    "#### VI. Despliegue\n",
    "\n",
    "Esta fase depende de los requerimientos, pudiendo ser simple como la generación de un reporte o compleja como la implementación de un proceso de explotación de información que atraviese a toda la organización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Herramientas'></a>\n",
    "## Herramientas\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "### Jupyter Notebooks\n",
    "- Proyecto open-source basado en IPython.\n",
    "- **Entorno interactivo** para la ejecución de código:\n",
    "    - Versionado de notebooks\n",
    "    - Celda como unidad de trabajo con un único formato (tipo de celda)\n",
    "    - Edición (cortar, copiar, pegar), merge, split y desplazamiento de celdas\n",
    "    - Visualización de celdas de diferentes tipos\n",
    "    - Inserción de celdas arriba y abajo (shortcut: 'A' para insertar arriba y 'B' abajo)\n",
    "    - Manejo de visualización de resultado (esconder, permitir scroll y borrar)\n",
    "    - Administración del Kernel (interrupción, reinicio, cambio)\n",
    "- Puede mostrar:\n",
    "    - `Código`\n",
    "    - Gráficas generadas a partir de código\n",
    "    - Texto enriqucido\n",
    "    - Expresiones matemáticas: $e^x=\\sum_{i=0}^\\infty \\frac{1}{i!}x^i$\n",
    "    - Dibujos y *rich media* (HTML, LaTeX, PNG, SVG, etc.)\n",
    "- **Lenguajes soportados**: Python, R, Scala y muchos más (ver [lista de kernels soportados](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels)).\n",
    "\n",
    "### Lenguaje R\n",
    "- Lenguaje de programación con fuerte foco en el análisis estadístico.\n",
    "- Ofrece una amplia variedad de herramientas y librerias para trabajar con datos\n",
    "\n",
    "    - **dplyr**: Libreria **R** para manipular data frames de forma simple: ```select```, ```filter```, etc. [https://dplyr.tidyverse.org/](https://dplyr.tidyverse.org/)\n",
    "\n",
    "    - Herramientas para data profiling: [DataExplorer](https://cran.r-project.org/web/packages/DataExplorer/vignettes/dataexplorer-intro.html), [HMisc](https://cran.r-project.org/web/packages/Hmisc/index.html), entre otros.\n",
    "    - Herramientas para data visualization: [ggplot2](https://ggplot2.tidyverse.org/)\n",
    "    \n",
    "### Lenguaje Python\n",
    "- Es otro de los lenguajes de programación elegido por la comunidad de data scientists.\n",
    "- Interpretado, de fácil aprendizaje y muy ligero.\n",
    "- Tiene una oferta de herramientas muy buena para data scientists:\n",
    "    - [Pandas](https://pandas.pydata.org/): Librería para manipulación de data frames.\n",
    "    - [Scikit-Learn](https://scikit-learn.org/stable/): Librería para mineria y análisis de datos, implementa algorítmos para los problemas clásicos de Machine Learning: Classification, Regression, Clustering.\n",
    "    - Herramientas para data visualization: [matplotlib](https://matplotlib.org/), [seaborn](https://seaborn.pydata.org/), [bokeh](https://bokeh.pydata.org/en/latest/).\n",
    "    - Librerías para profiling de datos: [Pandas Profiling](https://pypi.org/project/pandas-profiling/)\n",
    "    - Libreraías matemáticas: [NumPy](http://www.numpy.org/), [SciPy](https://www.scipy.org/), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Bibliografia'></a>\n",
    "## Bibliografía\n",
    "[Inicio ▲](#Indice)\n",
    "\n",
    "<ol>\n",
    "    <li>Wirth, R., & Hipp, J. (2000, April). CRISP-DM: Towards a standard process model for data mining. In Proceedings of the 4th international conference on the practical applications of knowledge discovery and data mining (pp. 29-39). Citeseer.\n",
    "    </li>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
